configfile: "config/config.yaml"

# This defines the number of negatives
NEGATIVES = config["negatives"]

# This defines the names of the negatives
DATASETS = ['N{}'.format(i+1) for i in range(0,NEGATIVES)]
# Append the 'positives'. Now a rule can expand on all datasets
DATASETS.append('positives')


include: "rules/get_data.smk"
include: "rules/pre_process.smk"
include: "rules/construct_datasets.smk"


rule all:
    input:
        # Raw data required
        # Produced by get_data.smk
        ancient("data/genomes/phages_refseq.fasta"),
        ancient("data/interactions/intact.txt"),
        ancient("data/pvogs/all.hmm"),
        ancient("data/pvogs/VOGProteinTable.txt"),
        ancient("data/taxonomy_db/taxa.sqlite"),
        ancient("data/taxonomy_db/taxa.sqlite.traverse.pkl"),

        # Pre-processing for calculating matrices
        # Produced by pre_process.smk
        "results/scores.tsv",
        "results/filtered_scores.tsv",
        "results/annotations.tsv",

         # Getting to pvogs from proteins and calcualating features
         # Produced by construct_datasets.smk
         expand(["results/interaction_datasets/{dataset}/{dataset}.interactions.tsv",
                "results/interaction_datasets/{dataset}/{dataset}.proteins.faa",
                "results/interaction_datasets/{dataset}/{dataset}.pvogs_interactions.tsv",
                "results/interaction_datasets/{dataset}/{dataset}.features.tsv"],
                dataset=DATASETS),

         # Major results
         # Produced by this Snakefile.
         "results/RF/best_model.pkl",
         "results/RF/best_model_id.txt",
         "results/predictions.tsv",
         "results/final_training_set.tsv",
         "results/predictions_annotations_features.tsv",
         "results/figures/fig_6.pdf"



checkpoint random_forest:
    input:
        expand(
            "results/interaction_datasets/{dataset}/{dataset}.features.tsv",
            dataset=DATASETS
            ),
        filtered_master_tsv = rules.filter_scores_table.output.filtered_master_tsv
    output:
        multiext("results/RF/figures/fig_1", ".pdf", ".svg", ".eps", ".png"),
        multiext("results/RF/figures/fig_2", ".pdf", ".svg", ".eps", ".png"),
        multiext("results/RF/figures/fig_3", ".pdf", ".svg", ".eps", ".png"),
        multiext("results/RF/figures/fig_4", ".pdf", ".svg", ".eps", ".png"),
        multiext("results/RF/figures/fig_5", ".pdf", ".svg", ".eps", ".png"),
        best_model = "results/RF/best_model.pkl",
        # This only contains the name as a string...
        best_model_id = "results/RF/best_model_id.txt",
    log:
        "results/analysis.py.ipynb"
    conda:
        "envs/pvogs_jupy.yml"
    threads:
        config['random_forest'].get('threads', 16)
    notebook:
        "notebooks/analysis.py.ipynb"


def get_best_model_id(wildcards):
    """
    Helper function to get the id of the dataset that gave the
    best results from the notebook search.
    """
    # Grab the last output file from the random_forest output
    checkpoint_output = checkpoints.random_forest.get(**wildcards).output[-1]
    with open(checkpoint_output, 'r') as fin:
        best_model_id = fin.read().strip()
    return best_model_id


rule predict:
    input:
        positives_features_tsv = "results/interaction_datasets/positives/positives.features.tsv",
        model_fp = "results/RF/best_model.pkl",
        filtered_scores_tsv = rules.filter_scores_table.output.filtered_master_tsv
    output:
        predictions_tsv = "results/predictions.tsv",
        final_training_set_tsv = "results/final_training_set.tsv"
    log:
        "results/.logs/predict.log"
    conda:
        "envs/pvogs_jupy.yml"
    params:
        # This is read from the notebook output
        dataset_string = get_best_model_id,
    threads:
        config["predict"].get("threads", 16)
    shell:
        "python workflow/scripts/predict.py "
        "-j {threads} "
        "-m {input.model_fp} "
        "-p {input.positives_features_tsv} "
        "-n results/interaction_datasets/{params.dataset_string}/{params.dataset_string}.features.tsv "
        "-t {input.filtered_scores_tsv} "
        "-o {output.predictions_tsv} "
        "&>{log}"

rule join_annotations_predictions:
    input:
        annotations_tsv = rules.parse_annotations.output.processed_annotations_fp,
        predictions_tsv = rules.predict.output.predictions_tsv
    output:
        final_table_tsv = "results/predictions_annotations_features.tsv"
    log:
        "results/.logs/join_annotations_predictions.log"
    conda:
        "envs/pvogs.yml"
    shell:
        "python workflow/scripts/join_annotations_predictions.py "
        "-i {input.predictions_tsv} "
        "-a {input.annotations_tsv} "
        "-o {output.final_table_tsv} "
        "&>{log}"

rule annotation_stats:
    input:
        annotations_tsv = rules.parse_annotations.output.processed_annotations_fp,
        final_table_tsv = rules.join_annotations_predictions.output.final_table_tsv
    output:
        multiext("results/figures/fig_6", ".pdf", ".svg", ".eps", ".png")
    log:
        "results/annotation_stats.py.ipynb"
    conda:
        "envs/pvogs_jupy.yml"
    notebook:
        "notebooks/annotation_stats.py.ipynb"
